{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import os \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk.data\n",
    "import string\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import numpy.linalg as la\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import scipy.spatial as spt\n",
    "from scipy.spatial import distance\n",
    "from pyemd import emd\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from numpy import dot, zeros, dtype, array, sqrt,double,array,sqrt, sum as np_sum\n",
    "import time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    numberOfFiles = len(r)\n",
    "    return r\n",
    "\n",
    "path = os.path.join(os.path.expanduser('~'), 'Downloads','LAB', 'summaries','docs')\n",
    "fnames = list_files(path)\n",
    "numberOfFiles = len(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### FirstLineAllPara....processedFirstLineAllPara,,,,, \n",
    "#processedAllList,,,,,rawAllList....\n",
    "#LastSentEachFile...processedLastSentEachFile\n",
    "\n",
    "paraFile = []\n",
    "processedAllList= []\n",
    "rawAllList =[]\n",
    "firstSentence = []\n",
    "lastSentence = []\n",
    "FirstLineAllPara = []\n",
    "LastPara =[]\n",
    "LastSentEachFile = []\n",
    "for name in (fnames):\n",
    "    with open(name, 'r') as f:\n",
    "        data = f.read().lower()\n",
    "        paragraphs = data.split(\"\\n\\n\")\n",
    "        paragraphs[:] = (value for value in paragraphs if value != '\\t')\n",
    "        LastPara.append(paragraphs[-1])\n",
    "    paraFile.extend(paragraphs)\n",
    "for i in range(len(LastPara)):\n",
    "    LasteachPara =[]\n",
    "    for j in (LastPara[i].strip().split('. ')):\n",
    "        LasteachPara.append(j)\n",
    "    LastSentEachFile.append(LasteachPara[-1])\n",
    "processedLastSentEachFile = []\n",
    "for i in range(len(LastSentEachFile)):\n",
    "    line = LastSentEachFile[i]\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    Str2 = ('\\n-----\\n'.join(sent_detector.tokenize(line.strip())))\n",
    "    Str2 = re.sub(' +', ' ', Str2)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(Str2)\n",
    "    Str1 = \" \".join(filter(lambda word: word not in stop_words, Str2.split()))\n",
    "    Str1 = re.sub(r'[^\\w\\s]','',Str1) \n",
    "    if(Str1 != ''):\n",
    "        processedLastSentEachFile.append(Str1)\n",
    "\n",
    "for para in range(len(paraFile)):\n",
    "    eachPara = paraFile[para]\n",
    "    for firstLine in (eachPara.strip().split('. ')):\n",
    "        FirstLineAllPara.append(firstLine)\n",
    "        break     \n",
    "processedFirstLineAllPara = []\n",
    "for i in range(len(FirstLineAllPara)):\n",
    "    line = FirstLineAllPara[i]\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    Str2 = ('\\n-----\\n'.join(sent_detector.tokenize(line.strip())))\n",
    "    Str2 = re.sub(' +', ' ', Str2)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(Str2)\n",
    "    Str1 = \" \".join(filter(lambda word: word not in stop_words, Str2.split()))\n",
    "    Str1 = re.sub(r'[^\\w\\s]','',Str1) \n",
    "    if(Str1 != ''):\n",
    "        processedFirstLineAllPara.append(Str1)\n",
    "processedList= []\n",
    "rawList = []   \n",
    "RawList = []\n",
    "sents = None\n",
    "text1 = None\n",
    "text1 = paraFile\n",
    "text =[]\n",
    "for elem in text1:\n",
    "    text.extend(elem.strip().split('. '))  \n",
    "\n",
    "sent = [el.replace('\\n', '') for el in text]\n",
    "if(sents ==None):\n",
    "    sents = sent\n",
    "else:\n",
    "    sents = sents+sent\n",
    "rawList = sents\n",
    "for i in range(len(rawList)):\n",
    "    l = rawList[i]\n",
    "    if(l != ''):\n",
    "        RawList.append(l)\n",
    "rawAllList = rawAllList+ RawList\n",
    "processedAllList =[]\n",
    "for i in range(len(rawAllList)):\n",
    "    line = rawAllList[i]\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    Str2 = ('\\n-----\\n'.join(sent_detector.tokenize(line.strip())))\n",
    "    Str2 = re.sub(' +', ' ', Str2)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(Str2)\n",
    "    Str1 = \" \".join(filter(lambda word: word not in stop_words, Str2.split()))\n",
    "    Str1 = re.sub(r'[^\\w\\s]','',Str1) \n",
    "    if(Str1 != ''):\n",
    "        processedList.append(Str1)\n",
    "            #medoids finding\n",
    "    processedAllList.append(Str1)        \n",
    "#lastSentence = processedAllList[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "### FirstLineAllPara....processedFirstLineAllPara,,,,, \n",
    "#processedAllList,,,,,rawAllList....\n",
    "#LastSentEachFile...processedLastSentEachFile\n",
    "print(len(processedAllList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec = None\n",
    "array = None\n",
    "global words_1\n",
    "global words_2\n",
    "global words_1_set\n",
    "global words_2_set\n",
    "removed_words = ['sdkls']\n",
    "W = np.memmap(\"data/embed.dat\", dtype=np.double, mode=\"r\", shape=(3000000, 300))\n",
    "with open(\"data/embed.vocab\") as f:\n",
    "    vocab_list = map(str.strip, f.readlines())\n",
    "vocab_dict = {w: k for k, w in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FileOpen(line1,line2):  \n",
    "    global woduplicates\n",
    "    global words_1\n",
    "    woduplicates = None\n",
    "    words_1 = line1.split()\n",
    "    words_1 = [token for token in words_1 if token in vocab_dict.keys()]\n",
    "    global words_2\n",
    "    words_2 = line2.split()\n",
    "    words_2 = [token for token in words_2 if token in vocab_dict.keys()] \n",
    "    woduplicates = set(words_1 + words_2)\n",
    "    return woduplicates\n",
    "def Dictionaty2Files(content, woduplicates):\n",
    "    doc_len = len(content)\n",
    "    d = []\n",
    "    for i, t in enumerate(woduplicates):\n",
    "        d.append(content.count(t) / float(doc_len))\n",
    "    return d \n",
    "def distance_matrix():\n",
    "    vocab_len = len(woduplicates)\n",
    "    distance_matrix = zeros((vocab_len, vocab_len), dtype=float)\n",
    "    for i, t1 in enumerate(woduplicates):\n",
    "        for j, t2 in enumerate(woduplicates):\n",
    "            distance_matrix[i][j] = sqrt(np_sum((W[[vocab_dict[t1]]] - W[[vocab_dict[t2]]])**2))\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fort', 'would', 'like', 'book']\n"
     ]
    }
   ],
   "source": [
    "allWords = [' '.join(processedAllList)]\n",
    "mostCommonWords = Counter(allWords[0].split()).most_common(5)\n",
    "reslist = [x[0] for x in mostCommonWords]\n",
    "res_list = [token for token in reslist if token in vocab_dict.keys()]\n",
    "print(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###GENERAL IDEA SENTENCES BASED ON MOST FREQUENT WORDS###\n",
    "combo =[]\n",
    "for w in range(len(res_list)):\n",
    "    word1 = res_list[w]\n",
    "    global woduplicates\n",
    "    global words_1\n",
    "    WMD_DICT = dict()\n",
    "    selectedAllSentences =[0,0]\n",
    "    M = len(processedAllList)\n",
    "    distanceMatrix = np.zeros((1,M))\n",
    "    Line = word1\n",
    "    for i in range(M):\n",
    "        Line1 = processedAllList[i]  \n",
    "        woduplicates = FileOpen(Line1,Line)\n",
    "        if(len(words_2)>0 and len(words_1)>0):\n",
    "            d1 = np.array(Dictionaty2Files(words_1, woduplicates), dtype=double)\n",
    "            d2 = np.array(Dictionaty2Files(words_2, woduplicates), dtype=double)\n",
    "            distance = distance_matrix()\n",
    "            distanceWMD = emd(d1,d2,distance)\n",
    "            WMD_DICT.update({(rawAllList[i],distanceWMD )})\n",
    "\n",
    "    sorted_K_WMD = (sorted(WMD_DICT.items(), key=lambda x:x[1]))\n",
    "    k = 5\n",
    "    sorted_K_WMD_array = np.asarray(sorted_K_WMD[0:k])\n",
    "    \n",
    "    combo.extend(list(sorted_K_WMD_array[:,0]))\n",
    "    \n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(combo)\n",
    "c_ = (c.most_common(5))\n",
    "SentFreqWords =res_list = [x[0] for x in c_] ####IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but every time i visit the fort it’s like a first', 'the illustrations in the comic book only ignited my curiosity about the fort further', 'happy at having spotted the famous gad (fort), which had made a distinct impact on my imagination, i would rush down from the terrace to share my exploit (of having spotted the fort) with anyone who was willing to hear.most times i would not find audience, and would retreat to the safe cocoon of amar chitra katha to validate my sighting.', 'just like my beloved sinhagad back home, it offers me a respite from the tugs and pulls of day-to-day life', 'i was fairly little and my grandfather would point at a distant hill in the hazy horizon and proudly declare, “to bagh, to sinhagad ahe” (look there, that’s sinhagad)']\n"
     ]
    }
   ],
   "source": [
    "print(SentFreqWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy at having spotted the famous gad (fort), which had made a distinct impact on my imagination, i would rush down from the terrace to share my exploit (of having spotted the fort) with anyone who was willing to hear.most times i would not find audience, and would retreat to the safe cocoon of amar chitra katha to validate my sighting.', 'a sombre shivaji and jijabai solemnly declaring “gad ala pan sinha gela” (the fort is won at the cost of the lion) on the last panel of the comic book would inadvertently burst open my floodgate of tears', 'having thus bawled out and almost inconsolable, i would seek out aaji (granny) and get her to read to me from ‘bokoba challe kashila’', 'a couple of times i also trekked up to its summit, eaten my worth in pithla bhaakri and bhaji and trekked down', 'something about the place remains essentially elusive', 'trekking up its ruined ramparts, one catches a majestic panorama of the rhine.', 'but on top here, like the poet john masefield, it is often the wind which rekindles my sehnsucht (yearning) for home.']\n"
     ]
    }
   ],
   "source": [
    "###GENERAL IDEA SENENCES FROM 1ST SENTENCE OF EACH PARAGRAPH\n",
    "\n",
    "### FirstLineAllPara....processedFirstLineAllPara,,,,, \n",
    "#processedAllList,,,,,rawAllList....\n",
    "#LastSentEachFile...processedLastSentEachFile\n",
    "leng = len(processedFirstLineAllPara)\n",
    "M =len(processedAllList)\n",
    "distanceMatrix = np.zeros((leng,M))\n",
    "for i in range(leng):\n",
    "    Line = processedFirstLineAllPara[i]\n",
    "    for j in range(M):\n",
    "        Line1 = processedAllList[j]  \n",
    "        woduplicates = FileOpen(Line,Line1)\n",
    "\n",
    "        if(len(words_2)>0 and len(words_1)>0):\n",
    "            d1 = np.array(Dictionaty2Files(words_1, woduplicates), dtype=double)\n",
    "            d2 = np.array(Dictionaty2Files(words_2, woduplicates), dtype=double)\n",
    "            distance = distance_matrix()\n",
    "            distanceWMD = emd(d1,d2,distance)\n",
    "            distanceMatrix[i][j] = distanceWMD\n",
    "            \n",
    "#print(FirstLineAllPara)\n",
    "SentFirstLine = []\n",
    "for row in range(leng):\n",
    "    minRow = min(i for i in distanceMatrix[row] if i > 0)\n",
    "    indesOfValuemin = np.where(distanceMatrix == minRow)\n",
    "    iandj = ([x[0] for x in indesOfValuemin])\n",
    "    i = iandj[0]\n",
    "    j = iandj[1]\n",
    "    #print(rawAllList[j])\n",
    "    SentFirstLine.append(rawAllList[j])\n",
    "print(SentFirstLine)### IMPORTANT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but on top here, like the poet john masefield, it is often the wind which rekindles my sehnsucht (yearning) for home.', 'the surrounding forest is aflame in shades of auburn and ochre like an incandescent candle glowing bright just before going out']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###GENERAL IDEA SENENCES FROM LAST SENTENCE OF EACH PARAGRAPH\n",
    "\n",
    "### FirstLineAllPara....processedFirstLineAllPara,,,,, \n",
    "#processedAllList,,,,,rawAllList....\n",
    "#LastSentEachFile...processedLastSentEachFile\n",
    "leng = len(processedLastSentEachFile)\n",
    "#print(processedLastSentEachFile)\n",
    "M =len(processedAllList)\n",
    "distanceMatrix = np.zeros((leng,M))\n",
    "for i in range(leng):\n",
    "    Line = processedLastSentEachFile[i]\n",
    "    for j in range(M):\n",
    "        Line1 = processedAllList[j]  \n",
    "        woduplicates = FileOpen(Line,Line1)\n",
    "\n",
    "        if(len(words_2)>0 and len(words_1)>0):\n",
    "            d1 = np.array(Dictionaty2Files(words_1, woduplicates), dtype=double)\n",
    "            d2 = np.array(Dictionaty2Files(words_2, woduplicates), dtype=double)\n",
    "            distance = distance_matrix()\n",
    "            distanceWMD = emd(d1,d2,distance)\n",
    "            distanceMatrix[i][j] = distanceWMD\n",
    "\n",
    "SentLastLine =[]\n",
    "#print(FirstLineAllPara)\n",
    "for row in range(leng):\n",
    "    minRow = min(i for i in distanceMatrix[row] if i > 0)\n",
    "    indesOfValuemin = np.where(distanceMatrix == minRow)\n",
    "    iandj = ([x[0] for x in indesOfValuemin])\n",
    "    i = iandj[0]\n",
    "    j = iandj[1]\n",
    "    SentLastLine.append(rawAllList[j])\n",
    "    \n",
    "    min2Row = min(i for i in distanceMatrix[row] if i > minRow)\n",
    "    indesOfValuemin = np.where(distanceMatrix == min2Row)\n",
    "    iandj = ([x[0] for x in indesOfValuemin])\n",
    "    i = iandj[0]\n",
    "    j = iandj[1]\n",
    "    SentLastLine.append(rawAllList[j])   \n",
    "print(SentLastLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GenralIdea = SentLastLine+SentFirstLine+SentFreqWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['but on top here, like the poet john masefield, it is often the wind which rekindles my sehnsucht (yearning) for home.', 'the surrounding forest is aflame in shades of auburn and ochre like an incandescent candle glowing bright just before going out', 'happy at having spotted the famous gad (fort), which had made a distinct impact on my imagination, i would rush down from the terrace to share my exploit (of having spotted the fort) with anyone who was willing to hear.most times i would not find audience, and would retreat to the safe cocoon of amar chitra katha to validate my sighting.', 'a sombre shivaji and jijabai solemnly declaring “gad ala pan sinha gela” (the fort is won at the cost of the lion) on the last panel of the comic book would inadvertently burst open my floodgate of tears', 'having thus bawled out and almost inconsolable, i would seek out aaji (granny) and get her to read to me from ‘bokoba challe kashila’', 'a couple of times i also trekked up to its summit, eaten my worth in pithla bhaakri and bhaji and trekked down', 'something about the place remains essentially elusive', 'trekking up its ruined ramparts, one catches a majestic panorama of the rhine.', 'but on top here, like the poet john masefield, it is often the wind which rekindles my sehnsucht (yearning) for home.', 'but every time i visit the fort it’s like a first', 'the illustrations in the comic book only ignited my curiosity about the fort further', 'happy at having spotted the famous gad (fort), which had made a distinct impact on my imagination, i would rush down from the terrace to share my exploit (of having spotted the fort) with anyone who was willing to hear.most times i would not find audience, and would retreat to the safe cocoon of amar chitra katha to validate my sighting.', 'just like my beloved sinhagad back home, it offers me a respite from the tugs and pulls of day-to-day life', 'i was fairly little and my grandfather would point at a distant hill in the hazy horizon and proudly declare, “to bagh, to sinhagad ahe” (look there, that’s sinhagad)']\n"
     ]
    }
   ],
   "source": [
    "print(len(processedAllList))\n",
    "print((GenralIdea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = len(GenralIdea)\n",
    "dist = np.zeros((l,l))\n",
    "for i in range(l):\n",
    "    Line = GenralIdea[i] \n",
    "    for j in range(l):\n",
    "        Line1 = GenralIdea[j]  \n",
    "        woduplicates = FileOpen(Line,Line1)\n",
    "\n",
    "        if(len(words_2)>0 and len(words_1)>0):\n",
    "            d1 = np.array(Dictionaty2Files(words_1, woduplicates), dtype=double)\n",
    "            d2 = np.array(Dictionaty2Files(words_2, woduplicates), dtype=double)\n",
    "            distance = distance_matrix()\n",
    "            distanceWMD = emd(d1,d2,distance)\n",
    "            dist[i][j] = distanceWMD\n",
    "            dist[j][i] = dist[i][j]\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "<<>>\n"
     ]
    }
   ],
   "source": [
    "#Line =\"group islands about 1,500 km from Australia same distance New Zealand\"\n",
    "#Line1 = \"chain islands near Tropic Capricorn some 1,500 km north Australia\"\n",
    "#Line1 = \"India officially Republic India country South Asia It seventh largest country by area second most populous country over 1.2 billion people  most populous democracy world Bounded Indian Ocean south Arabian Sea south west  Bay Bengal south east it shares land borders Pakistan west China Nepal Bhutan north east Myanmar Burma Bangladesh east Indian Ocean India vicinity Sri Lanka Maldives addition India Andaman Nicobar Islands share maritime border with Thailand Indonesia\"\n",
    "#Line = \"New Caledonia group islands about 1,500 km Australia same distance New Zealan Over 80% New Caledonians reside main island where capital Noumea located economy French colony based mining recent years tourism increasingly important Lost wind surfers scuba divers snorkelers attracted islands where they can enjoy numerous boutiques museums restaurants which offer many types ethic food addition zoo botanical gardens aquarium Noumea worth seeing All sort accommodations available from five star hotels simple tribal lodgings French official language English widely spoken places with lots tourists\"\n",
    "#Line = \"India famous country all over the world Geographically our country located south Asia continent India high population country well protected all directions naturally It famous country great cultural traditional values all across world It contains mountain called Himalaya which biggest world It surrounded three big oceans from three directions such south with Indian Ocean east with Bay of Bengal west with Arabic sea India democratic country ranks second its population national language India Hindi however almost fourteen nationally recognized languages spoken here\"\n",
    "#Line = \"New Caledonia chain islands near Tropic Capricorn some 1,500 km north Australia main island home 80% residents this French colony Mining dominant industry decades though tourism more more significant part economy islands haven wind surfers scuba divers snorkelers golfers Noumea capital city with  French atmosphere boutiques museums restaurants tourist attractions particularly worth seeing zoo botanical gardens aquarium full spectrum accommodations available New Caledonia English widely spoken places where tourists frequent though French official language there many different Melanesian dialects\"\n",
    "#Line = \"India beautiful country famous all over world unique cultures traditions It famous for historical heritages monuments Citizens here very polite understanding nature It slave country earlier 1947 under British rule However after many years hard struggles sacrifices great Indian freedom fighters India got freedom from British rule 1947 Pt Jawaharlal Nehru became first Prime Minister India hoisted Indian flag when India got freedom he proclaimed that When world sleeps India wake life freedom India democratic country where its public authorized take decisions betterment country India famous country for saying Unity Diversity because people  many religions castes culture tradition live together with unity Most Indian heritages monuments have been added to world heritage sites\"\n",
    "woduplicates = FileOpen(Line,Line1)\n",
    "if(len(words_2)>0 and len(words_1)>0):\n",
    "    d1 = np.array(Dictionaty2Files(words_1, woduplicates), dtype=double)\n",
    "    d2 = np.array(Dictionaty2Files(words_2, woduplicates), dtype=double)\n",
    "    distance = distance_matrix()\n",
    "#print(Line)\n",
    "#print(Line1)\n",
    "distanceWMD = emd(d1,d2,distance)\n",
    "print(distanceWMD)\n",
    "print(\"<<>>\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
